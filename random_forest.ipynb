{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Berkeley\\Job\\Pixiv\\Random_forest\\random_forest.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000001?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000001?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000001?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential, Model\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000001?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000001?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yhb19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# https://youtu.be/vgdFovAZUzM\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "Annotate images at www.apeer.com to create labels. \n",
    "Code last tested on: \n",
    "    Tensorflow: 2.2.0\n",
    "    Keras: 2.3.1\n",
    "    Python: 3.7\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 14.7 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.9.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Berkeley\\Job\\Pixiv\\Random_forest\\random_forest.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m\"\u001b[39;49m\u001b[39mimages/\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39m#Resizing images is optional, CNNs are ok with large images\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Berkeley/Job/Pixiv/Random_forest/random_forest.ipynb#ch0000000?line=3'>4</a>\u001b[0m SIZE_X \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m#Resize images (height  = X, width = Y)\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'images/'"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"images/\"))\n",
    "\n",
    "#Resizing images is optional, CNNs are ok with large images\n",
    "SIZE_X = 1024 #Resize images (height  = X, width = Y)\n",
    "SIZE_Y = 996\n",
    "\n",
    "#Capture training image info as a list\n",
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"images/train_images\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "train_masks = [] \n",
    "for directory_path in glob.glob(\"images/train_masks\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "        train_masks.append(mask)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)\n",
    "\n",
    "#Use customary x_train and y_train variables\n",
    "X_train = train_images\n",
    "y_train = train_masks\n",
    "y_train = np.expand_dims(y_train, axis=3) #May not be necessary.. leftover from previous code \n",
    "\n",
    "\n",
    "#Load VGG16 model wothout classifier/fully connected layers\n",
    "#Load imagenet weights that we are going to use as feature generators\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE_X, SIZE_Y, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "#After the first 2 convolutional layers the image dimension changes. \n",
    "#So for easy comparison to Y (labels) let us only take first 2 conv layers\n",
    "#and create a new model to extract features\n",
    "#New model with only first 2 conv layers\n",
    "new_model = Model(inputs=VGG_model.input, outputs=VGG_model.get_layer('block1_conv2').output)\n",
    "new_model.summary()\n",
    "\n",
    "#Now, let us apply feature extractor to our training data\n",
    "features=new_model.predict(X_train)\n",
    "\n",
    "#Plot features to view them\n",
    "square = 8\n",
    "ix=1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        ax = plt.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(features[0,:,:,ix-1], cmap='gray')\n",
    "        ix +=1\n",
    "plt.show()\n",
    "\n",
    "#Reassign 'features' as X to make it easy to follow\n",
    "X=features\n",
    "X = X.reshape(-1, X.shape[3])  #Make it compatible for Random Forest and match Y labels\n",
    "\n",
    "#Reshape Y to match X\n",
    "Y = y_train.reshape(-1)\n",
    "\n",
    "#Combine X and Y into a dataframe to make it easy to drop all rows with Y values 0\n",
    "#In our labels Y values 0 = unlabeled pixels. \n",
    "dataset = pd.DataFrame(X)\n",
    "dataset['Label'] = Y\n",
    "print(dataset['Label'].unique())\n",
    "print(dataset['Label'].value_counts())\n",
    "\n",
    "##If we do not want to include pixels with value 0 \n",
    "##e.g. Sometimes unlabeled pixels may be given a value 0.\n",
    "dataset = dataset[dataset['Label'] != 0]\n",
    "\n",
    "#Redefine X and Y for Random Forest\n",
    "X_for_RF = dataset.drop(labels = ['Label'], axis=1)\n",
    "Y_for_RF = dataset['Label']\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "model.fit(X_for_RF, Y_for_RF) \n",
    "\n",
    "#Save model for future use\n",
    "filename = 'RF_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "#Load model.... \n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Test on a different image\n",
    "#READ EXTERNAL IMAGE...\n",
    "test_img = cv2.imread('images/test_images/Sandstone_Versa0360.tif', cv2.IMREAD_COLOR)       \n",
    "test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "#predict_image = np.expand_dims(X_train[8,:,:,:], axis=0)\n",
    "X_test_feature = new_model.predict(test_img)\n",
    "X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])\n",
    "\n",
    "prediction = loaded_model.predict(X_test_feature)\n",
    "\n",
    "#View and Save segmented image\n",
    "prediction_image = prediction.reshape(mask.shape)\n",
    "plt.imshow(prediction_image, cmap='gray')\n",
    "plt.imsave('images/test_images/360_segmented.jpg', prediction_image, cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0eaf9693369166616973fac007afc14aa16fc29bcf659f2810ba1a115a17081"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
